{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Semi-structured and structured data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lecture index\n",
    " - the structure spectrum\n",
    " - files: formats and performance\n",
    " - Tabular Data: Examples, Challenges, pySpark DataFrames\n",
    " - Log files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Key Data Management Concepts\n",
    " - Data Model: 데이터를 묘사하기 위한 concepts의 집단\n",
    " - Schema: 주어진 Data model를 사용한 특정 데이터 집단의 묘사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Structure Spectrum\n",
    "![spectrum](http://postfiles4.naver.net/20150716_179/valtin_1437027008345FOLW6_JPEG/1.jpg?type=w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file이란?\n",
    " - byte들의 이름 지어진 순서 (일반적으로 페이지들의 집단으로 저장됨)\n",
    " - Filesystem 은 계층적인 namespace 내의 구성된 파일들의 집단으로\n",
    "   - 물리적 매체에서 byte들의 lay out을 맡고 있고\n",
    "   - file metadata를 저장하고\n",
    "   - 파일들과의 interaction을 위한 API를 제공\n",
    " - standard operations\n",
    "   * open() / close()\n",
    "   * seek()\n",
    "   * read() / write()\n",
    " - filesystem의 root\n",
    "   * 리눅스 - / , 윈도우 - \\\n",
    " - 파일과 디렉토리는 서로 관련된 권한을 가지고 있지만 파일들은 언제나 계층적으로 배치되어 있지는 않다\n",
    "   * Content-addressable storage (CAS)\n",
    "   * Often used for large multimedia collections\n",
    " \n",
    "### File format 을 위한 고려사항\n",
    " - Data model: tabular, hierarchical, array\n",
    " - physical layout\n",
    " - Field units and validation\n",
    " - metadata  header, side file, specification, other?\n",
    " - Plain text or binary\n",
    " - Delimiters and escaping\n",
    " - Compression, encryption, checksums?\n",
    " - Schema evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Semi-structured Tabular Data\n",
    " - 가장 자주쓰는 데이터 포맷중 하나\n",
    " - 표는 행과 열의 집단이다\n",
    " - 각 행은 index를 가지고 있고, 각 열은 이름을 가지고 있다\n",
    " - 한 cell은 index와 name 쌍으로 특정지어진다\n",
    " - cell은 값을 갖을 수도, 갖지 않을 수도 있다.\n",
    " - 각 cell의 type은 그 값으로부터 추론된다\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data Example\n",
    " * Fortune 500 companies\n",
    "![fortune](http://postfiles8.naver.net/20150716_167/valtin_1437031334286lSBKm_JPEG/2.jpg?type=w3)\n",
    " http://fortune.com/fortune500/\n",
    " \n",
    " 이 예시를 CSV하여 변환\n",
    " \n",
    " ![fortune CSV](http://postfiles15.naver.net/20150716_110/valtin_1437031334495hn49L_JPEG/3.jpg?type=w3)\n",
    " \n",
    " 또 다른 예시인 Protein Data Bank\n",
    " \n",
    " ![PDB](http://postfiles14.naver.net/20150716_29/valtin_1437031334708nkApL_JPEG/4.jpg?type=w3)\n",
    " http://www.rcsb.org/pdb/files/3J2T.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##위의 예시들로 추론할수 있는 문제점\n",
    " 1. Tabular data\n",
    "   - 형식이 잘 정립되어 있지 않다.\n",
    "   - 결측치가 있을 수 있다\n",
    "   - 타입이 정확하게 추론 되지 않는다 (e.g., \"2\" 와 \"2.0\")\n",
    "   - format의 versioning 을 위한 지원이 없다\n",
    " 2. from multiple source\n",
    "     * 결측 필드가 있다.(모든 소스에서 같은 데이터를 제공하지 않는다)\n",
    "     * 데이터 타입이 일관되지 않을 수 있다\n",
    "     * 같은 entity에서 일관되지 않은 값이 있을 수 있다. (Wal-Mart 와 WalMart)\n",
    " 3. from Sensors\n",
    "     * 결측 필드가 있다\n",
    "     * 센서의 손상이 있을 수 있다\n",
    "     * timestamp가 정확하지 않을 수 있다\n",
    "     * 다른 metadata가 에러를 가질 수 있다\n",
    "     * 센서가 잠시동안 offline이 될 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##pandas: Pyhton Data Analysis Library\n",
    " * 오픈소스 기반 데이터 분석 및 모델링 라이브러리\n",
    "  - An alternative to using R\n",
    " * Pandas DataFrame: a table with named columns\n",
    "  - Pandas object에서 가장 자주 사용됨\n",
    "  - 파이썬 Dict로 표현 (Column_name -> Series)\n",
    "    * I-D labeled array capable of holding any data type\n",
    "  - R 또한 비슷한 데이터 프레임 타입을 가지고 있다\n",
    "   \n",
    "##Semi-Structured Data in pySpark\n",
    " * RDDS의 확장으로 Spark 1.3에서 Dataframes 가 소개됨\n",
    " * named columns(열)로 구성된 데이터의 분산된 집단\n",
    "   - Pandas와 R dataframes은 같지만, Pandas는 분산되어져 있다\n",
    " * 값으로부터 열의 타입을 추론할 수 있다\n",
    " \n",
    "##pySpark and Pandas DataFrames\n",
    " * Pandas와 pySpark는 쉽게 전환할 수 있다\n",
    "  \n",
    " - convert spark dataframe to pandas\n",
    "   * pandas_df = spark_df.toPandas()\n",
    " - Create a park Dataframe from Pandas\n",
    "   * spark_df = context.createDataFrame(pandas_df)\n",
    "\n",
    "## pySpark DataFrame Performance\n",
    " * 싱글 머신에서 약 5배 정도 pyspark performance가 높다\n",
    " ![performance](http://postfiles11.naver.net/20150716_154/valtin_1437034010888cz8Sj_JPEG/5.jpg?type=w3)\n",
    " https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html\n",
    " \n",
    "##Semi-Structured Log files\n",
    " * 서버에서 printf 명령어로 만들어짐\n",
    " * 사람이 읽을수 있는 텍스트 형식 파일\n",
    " * Format published or “defined” by code\n",
    "   - parse 하기 매우 어렵다\n",
    "\n",
    "#Recall: Apache Web Server Log\n",
    "![log](http://postfiles15.naver.net/20150716_46/valtin_1437034252811xMmJX_JPEG/6.jpg?type=w3)\n",
    "\n",
    " * 예시 라인\n",
    " ![line](http://postfiles3.naver.net/20150716_194/valtin_1437034348116900wC_JPEG/7.jpg?type=w3)\n",
    "   \n",
    "   \n",
    " * 부분 분석\n",
    "   - 127.0.0.1 클라이언트 IP 주소\n",
    "   - \"-\" 원격 머신으로부터 유저 분석\n",
    "   - \"-\" 로컬 로그온으로부터 유저 분석\n",
    "     * 둘다 \"-\"은 not available을 의미\n",
    "   - [01/Aug/1995:00:00:01 -0400] 요청 시간\n",
    "   - \"GET/images/launch-logo.gifHTTP/1.0\" 클라이언트 요청\n",
    "   - 200 서버가 클라이언트에게 보내는 상태 코드\n",
    "     * OK response (2XX), others: 3XX,4XX,5XX\n",
    "   - 1839 클라이언트에게 return 된 object의 사이즈\n",
    "     * 만약 return된 내용이 없다면 \"-\" 나 가끔 \"0\"가 return됨\n",
    "     \n",
    "##Some Log Analysis Questions\n",
    " * Overall\n",
    "   - 리턴 된 컨텐츠나 사이즈, 상태를 위한 statistics는 무엇인가?\n",
    "   - 리턴 코드들의 타입은 무엇인가?\n",
    "   - 얼마나 많이 page not found 에러가 떴는가?\n",
    " * temporal\n",
    "   - 하루에 얼마나 많은 unique hosts들이 왔는가\n",
    "   - 하루에 얼마나 많은 요청이 있었는가\n",
    "   - 평균적으로 호스트당 얼마나 많은 요청이 있는가?\n",
    "   - 하루에 얼마나 404 에러가 떴는가?\n",
    "   \n",
    "##Splunk\n",
    " - 여러 컴퓨터부터 파일들을 수집\n",
    "   * 어플리케이션과 시스템 이벤트 로그\n",
    " - 일반적이지 않은 이벤트 확인:\n",
    "   * 디스크 에러\n",
    "   * 네트워크 혼잡\n",
    "   * 보안 공격\n",
    " - 리소스 모니터링\n",
    "   * 네트워크, 메모리, 디스크 등\n",
    " - dashboard로 시각화\n",
    "\n",
    "##File performance consideration\n",
    " * 읽기 vs 쓰기 성능\n",
    " * Plain text vs binary format\n",
    " * Environment: Pandas(python) vs Scala/java\n",
    " * uncompressed vs compressed\n",
    "\n",
    "##File Performance\n",
    " >![performance](http://postfiles6.naver.net/20150716_133/valtin_1437038727881KjKzB_JPEG/8.jpg?type=w3)\n",
    " \n",
    " * Pandas는 binary file I/O library를 가지고 있지 않음\n",
    "   - 따로 사용하는 라이브러리에 따라 성능이 좌우됨\n",
    " * binary file 이 일반 텍스트 보다 훨씬 빠름\n",
    "\n",
    "## file performance - compression\n",
    "![comp](http://postfiles16.naver.net/20150716_159/valtin_1437039047510AD5KI_JPEG/9.jpg?type=w3)\n",
    "\n",
    " - compressed read 가 write 보다 훨씬 빠름\n",
    "   * LZ4 가 gzip 보다 더 좋음\n",
    "   * LZ4 compression times approach raw I/O times\n",
    "   \n",
    "##Structured data\n",
    " - 데이터의 20%정보만이 정형화되어 있다\n",
    " - 미디어 어플리케이션, enterprise search, consumer application에 의해 감소중이다\n",
    " >\n",
    " - 보통 관계형 DB로 표현되는데, 각각 Schema와 instance로 구성되어 있다\n",
    "  * Schema: 각 관계의 특정한 이름과 열의 이름 및 타입\n",
    "  * Instance: 주어진 시간에서 실제 데이터\n",
    "    - rows = cardinality\n",
    "    - fields = degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
